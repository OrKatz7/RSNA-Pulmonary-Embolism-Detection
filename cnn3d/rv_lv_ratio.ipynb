{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U torch\n",
    "# !pip install -U torchvision\n",
    "# !pip install -U pillow==6.2.0\n",
    "# !pip install -q monai\n",
    "# !pip install -q git+https://github.com/ildoonet/pytorch-gradual-warmup-lr.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "CFG = {\n",
    "    'image_target_cols': [\n",
    "        'pe_present_on_image', # only image level\n",
    "    ],\n",
    "    'exam_target_cols': [\n",
    "        'negative_exam_for_pe', # exam level\n",
    "        'rv_lv_ratio_gte_1', # exam level\n",
    "        'rv_lv_ratio_lt_1', # exam level\n",
    "        'leftsided_pe', # exam level\n",
    "        'chronic_pe', # exam level\n",
    "        'rightsided_pe', # exam level\n",
    "        'acute_and_chronic_pe', # exam level\n",
    "        'central_pe', # exam level\n",
    "        'indeterminate' # exam level\n",
    "    ], \n",
    "    'image_weight': 0.07361963,\n",
    "    'exam_weights': [0.0736196319, 0.2346625767, 0.0782208589, 0.06257668712, 0.1042944785, 0.06257668712, 0.1042944785, 0.1877300613, 0.09202453988],\n",
    "}\n",
    "def rsna_metric(label, predicted ,bce_func = torch.nn.BCELoss(reduction='none'),CFG=CFG):\n",
    "\n",
    "    y_pred_exam = predicted\n",
    "    y_true_exam = label\n",
    "                \n",
    "    total_loss = torch.tensor(0, dtype=torch.float32).cuda()\n",
    "    total_weights = torch.tensor(0, dtype=torch.float32).cuda()\n",
    "    \n",
    "    label_w = torch.tensor(CFG['exam_weights']).view(1, -1).cuda()\n",
    "    \n",
    "    exam_loss = bce_func(y_pred_exam, y_true_exam)\n",
    "    exam_loss = torch.sum(exam_loss*label_w, 1)[0] # Kaggle us\n",
    "    \n",
    "    total_loss += exam_loss\n",
    "    total_weights += label_w.sum()\n",
    "    final_loss = total_loss.cuda()/total_weights.cuda()\n",
    "    return final_loss\n",
    "\n",
    "class RsnaLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RsnaLoss, self).__init__()\n",
    "        self.rsna_metric = rsna_metric\n",
    "    def forward(self,predicted,label):\n",
    "        rsna = self.rsna_metric(label, predicted)\n",
    "        return rsna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import monai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'#1,2,3' # specify GPUs locally\n",
    "\n",
    "# libraries\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import PIL.Image\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tqdm import tqdm as tqdm\n",
    "from sklearn.metrics import cohen_kappa_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader,Dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data.sampler import SubsetRandomSampler, RandomSampler, SequentialSampler\n",
    "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau, CosineAnnealingLR\n",
    "from warmup_scheduler import GradualWarmupScheduler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import albumentations\n",
    "\n",
    "import monai\n",
    "from monai.data import NiftiDataset\n",
    "from monai.transforms import AddChannel, Compose, RandRotate90, Resize, ScaleIntensity, ToTensor\n",
    "\n",
    "from apex import amp # I cannot install apex in Kagggle notebook\n",
    "\n",
    "device = torch.device('cuda')\n",
    "\n",
    "def set_seed(seed=0):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)  \n",
    "    torch.cuda.manual_seed(seed)  \n",
    "    torch.cuda.manual_seed_all(seed)  \n",
    "#     torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "set_seed(7777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = False\n",
    "\n",
    "kernel_type = 'densenet121'\n",
    "\n",
    "image_size = 160\n",
    "use_amp = False\n",
    "data_dir = '../Datasets/RSNA/train256/train-jpegs'\n",
    "num_workers = 32\n",
    "init_lr = 1e-5\n",
    "out_dim = 1\n",
    "freeze_epo = 0\n",
    "warmup_epo = 1\n",
    "cosine_epo = 2 if DEBUG else 19\n",
    "n_epochs = freeze_epo + warmup_epo + cosine_epo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_cols = [\n",
    "#         'negative_exam_for_pe', # exam level\n",
    "        'rv_lv_ratio_gte_1', # exam level\n",
    "#         'rv_lv_ratio_lt_1', # exam level\n",
    "#         'leftsided_pe', # exam level\n",
    "#         'chronic_pe', # exam level\n",
    "#         'rightsided_pe', # exam level\n",
    "#         'acute_and_chronic_pe', # exam level\n",
    "#         'central_pe', # exam level\n",
    "#         'indeterminate' # exam level\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../Datasets/RSNA/train.csv')\n",
    "df = df[(df.rv_lv_ratio_gte_1 == 1) | ( df.rv_lv_ratio_lt_1==1)].reset_index(drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "np.random.seed(0)\n",
    "group_kfold = GroupKFold(n_splits=5)\n",
    "print(group_kfold)\n",
    "\n",
    "df['fold'] = -1\n",
    "for i, (_, val_index) in enumerate(group_kfold.split(df, groups=df.StudyInstanceUID)):\n",
    "    df.loc[val_index, 'fold'] = i\n",
    "\n",
    "df.fold.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_study = df.drop_duplicates('StudyInstanceUID')[['StudyInstanceUID','SeriesInstanceUID','fold']+target_cols]\n",
    "if DEBUG:\n",
    "    df_study = df_study.head(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preper(row):\n",
    "    jpg_lst = sorted(glob(os.path.join(data_dir, row.StudyInstanceUID, row.SeriesInstanceUID, '*.jpg')))\n",
    "    img_lst = [cv2.imread(jpg)[:,:,::-1] for jpg in jpg_lst] \n",
    "    img = np.stack([image.astype(np.float32) for image in img_lst], axis=2).transpose(3,0,1,2)\n",
    "    return row.StudyInstanceUID,img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_imgs ={}\n",
    "# for index,row in tqdm(df_study.iterrows()):\n",
    "#     jpg_lst = sorted(glob(os.path.join(data_dir, row.StudyInstanceUID, row.SeriesInstanceUID, '*.jpg')))\n",
    "#     img_lst = [cv2.imread(jpg)[:,:,::-1] for jpg in jpg_lst] \n",
    "#     img = np.stack([image.astype(np.float32) for image in img_lst], axis=2).transpose(3,0,1,2)\n",
    "#     all_imgs[row.StudyInstanceUID] = img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "from glob import glob\n",
    "from monai.transforms import LoadNifti, Randomizable, apply_transform\n",
    "from monai.transforms import AddChannel, Compose, RandRotate90, Resize, ScaleIntensity, ToTensor, RandAffine\n",
    "from monai.utils import get_seed\n",
    "from tqdm.auto import tqdm\n",
    "# x = Parallel(n_jobs=32)(delayed(preper)(row) for index,row in tqdm(df_study.iterrows()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_imgs ={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for row in x:\n",
    "#     all_imgs[row[0]] = row[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RSNADataset3D(torch.utils.data.Dataset, Randomizable):\n",
    "    def __init__(self, csv, mode, transform=None):\n",
    "\n",
    "        self.csv = csv.reset_index()\n",
    "        self.mode = mode\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.csv.shape[0]\n",
    "    \n",
    "    def randomize(self) -> None:\n",
    "        MAX_SEED = np.iinfo(np.uint32).max + 1\n",
    "        self._seed = self.R.randint(MAX_SEED, dtype=\"uint32\")    \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        self.randomize()\n",
    "        row = self.csv.iloc[index]\n",
    "        jpg_lst = sorted(glob(os.path.join(data_dir, row.StudyInstanceUID, row.SeriesInstanceUID, '*.jpg')))\n",
    "        img_lst = np.array([cv2.imread(jpg)[:,:,::-1] for jpg in jpg_lst]) #z,y,x\n",
    "#         print(img_lst.shape)\n",
    "#         if np.random.randint(2)==0 and self.mode=='train':\n",
    "#             img_lst = img_lst[::-1]\n",
    "#         if np.random.randint(2)==0 and self.mode=='train':\n",
    "#             z = np.random.randint(1,10)\n",
    "#             y = np.random.randint(3,30)\n",
    "#             x = np.random.randint(3,30)\n",
    "#             img_lst = img_lst[z:-z,x:-x,y:-y]\n",
    "#             print(\"flip\")\n",
    "        img = np.stack([image.astype(np.float32) for image in img_lst], axis=2).transpose(3,0,1,2)\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            if isinstance(self.transform, Randomizable):\n",
    "                self.transform.set_random_state(seed=self._seed)\n",
    "            img = apply_transform(self.transform, img)\n",
    "            \n",
    "        if self.mode == 'test':\n",
    "            return img\n",
    "        else:\n",
    "            return img, torch.tensor(row[target_cols]).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def default_collate(batch):\n",
    "    data = torch.stack([item[0] for item in batch])\n",
    "    target = torch.stack([item[1] for item in batch])  # image labels.\n",
    "    return data, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = Compose([ScaleIntensity(), \n",
    "                            Resize((image_size, image_size, image_size)), \n",
    "                            RandAffine( \n",
    "                                      prob=0.5,\n",
    "#                                       rotate_range=(np.pi * 2, np.pi * 2, np.pi * 2),\n",
    "                                      scale_range=(0.15, 0.15, 0.15),\n",
    "                                      padding_mode='border'),\n",
    "                            ToTensor()])\n",
    "val_transforms = Compose([ScaleIntensity(),Resize((image_size, image_size, image_size)),ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img, label = dataset_show[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_show = RSNADataset3D(df_study.head(5), 'train', transform=val_transforms)\n",
    "dataset_show_aug = RSNADataset3D(df_study.head(5), 'train', transform=train_transforms)\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 20,5\n",
    "for i in range(5):\n",
    "    f, axarr = plt.subplots(1,6)\n",
    "    img, label = dataset_show[i]\n",
    "    for j in range(6):        \n",
    "        if j<=2: axarr[j].imshow(img.numpy().transpose(1,2,3,0).mean(axis=j))\n",
    "        elif j==3: axarr[j].imshow(img.numpy().transpose(1,2,3,0)[image_size//2,:,:])\n",
    "        elif j==4: axarr[j].imshow(img.numpy().transpose(1,2,3,0)[:,image_size//2,:])\n",
    "        elif j==5: axarr[j].imshow(img.numpy().transpose(1,2,3,0)[:,:,image_size//2])\n",
    "        axarr[j].set_title(f\"Orig {i}\")\n",
    "    f, axarr = plt.subplots(1,6)\n",
    "    img, label = dataset_show_aug[i]  \n",
    "    img = torch.nn.functional.interpolate(img.unsqueeze(0), size=(160,160,160))[0]\n",
    "    for j in range(6):        \n",
    "        if j<=2: axarr[j].imshow(img.numpy().transpose(1,2,3,0).mean(axis=j))\n",
    "        elif j==3: axarr[j].imshow(img.numpy().transpose(1,2,3,0)[image_size//2,:,:])\n",
    "        elif j==4: axarr[j].imshow(img.numpy().transpose(1,2,3,0)[:,image_size//2,:])\n",
    "        elif j==5: axarr[j].imshow(img.numpy().transpose(1,2,3,0)[:,:,image_size//2])\n",
    "        axarr[j].set_title(f\"Aug {i}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bce = nn.BCEWithLogitsLoss(weight= torch.tensor(CFG['exam_weights']).view(-1).cuda())\n",
    "bce = nn.BCEWithLogitsLoss()\n",
    "def criterion(logits, target): \n",
    "    loss = bce(logits.cuda(), target.cuda())\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, optimizer):\n",
    "\n",
    "    model.train()\n",
    "    train_loss = []\n",
    "    bar = tqdm(loader)\n",
    "    for (data, target) in bar:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "#         data = torch.nn.functional.interpolate(data, size=(160,160,160))\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(data)       \n",
    "        loss = criterion(logits, target)\n",
    "\n",
    "        if not use_amp:\n",
    "            loss.backward()\n",
    "        else:\n",
    "            with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "                scaled_loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_np = loss.detach().cpu().numpy()\n",
    "        train_loss.append(loss_np)\n",
    "        smooth_loss = sum(train_loss[-100:]) / min(len(train_loss), 100)\n",
    "        bar.set_description('loss: %.5f, smth: %.5f' % (loss_np, smooth_loss))\n",
    "    return train_loss\n",
    "\n",
    "\n",
    "def val_epoch(model, loader, is_ext=None, n_test=1, get_output=False):\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = []\n",
    "    LOGITS = []\n",
    "    TARGETS = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for (data, target) in tqdm(loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "#             data = torch.nn.functional.interpolate(data, size=(160,160,160))\n",
    "            logits = model(data)\n",
    "            LOGITS.append(logits.detach().cpu())\n",
    "            TARGETS.append(target.detach().cpu())\n",
    "\n",
    "    val_loss = criterion(torch.cat(LOGITS), torch.cat(TARGETS)).cpu().numpy()\n",
    "    PROBS = torch.sigmoid(torch.cat(LOGITS)).cpu().numpy().squeeze()    \n",
    "    LOGITS = torch.cat(LOGITS).cpu().numpy()\n",
    "    TARGETS = torch.cat(TARGETS).cpu().numpy()\n",
    "    \n",
    "    if get_output:\n",
    "        return LOGITS, PROBS, TARGETS\n",
    "    else:\n",
    "        acc = (PROBS.round() == TARGETS).mean() * 100.\n",
    "        auc = roc_auc_score(TARGETS, LOGITS)\n",
    "        return float(val_loss), acc, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradualWarmupSchedulerV2(GradualWarmupScheduler):\n",
    "    def __init__(self, optimizer, multiplier, total_epoch, after_scheduler=None):\n",
    "        super(GradualWarmupSchedulerV2, self).__init__(optimizer, multiplier, total_epoch, after_scheduler)\n",
    "    def get_lr(self):\n",
    "        if self.last_epoch > self.total_epoch:\n",
    "            if self.after_scheduler:\n",
    "                if not self.finished:\n",
    "                    self.after_scheduler.base_lrs = [base_lr * self.multiplier for base_lr in self.base_lrs]\n",
    "                    self.finished = True\n",
    "                return self.after_scheduler.get_lr()\n",
    "            return [base_lr * self.multiplier for base_lr in self.base_lrs]\n",
    "        if self.multiplier == 1.0:\n",
    "            return [base_lr * (float(self.last_epoch) / self.total_epoch) for base_lr in self.base_lrs]\n",
    "        else:\n",
    "            return [base_lr * ((self.multiplier - 1.) * self.last_epoch / self.total_epoch + 1.) for base_lr in self.base_lrs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# monai.networks.nets.senet.se_resnext50_32x4d?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(fold):\n",
    "    df_train = df_study[(df_study['fold'] != fold)]\n",
    "    df_valid = df_study[(df_study['fold'] == fold)]\n",
    "\n",
    "    dataset_train = RSNADataset3D(df_train, 'train', transform=train_transforms)\n",
    "    dataset_valid = RSNADataset3D(df_valid, 'val', transform=val_transforms)\n",
    "    train_loader = torch.utils.data.DataLoader(dataset_train, batch_size=9, sampler=RandomSampler(dataset_train), num_workers=num_workers)\n",
    "    valid_loader = torch.utils.data.DataLoader(dataset_valid, batch_size=9, num_workers=num_workers)\n",
    "\n",
    "#     model = monai.networks.nets.senet.se_resnext101_32x4d(spatial_dims=3, in_channels=3, num_classes=out_dim).to(device)\n",
    "    model = monai.networks.nets.densenet.densenet121(spatial_dims=3, in_channels=3, out_channels=out_dim).to(device)\n",
    "\n",
    "    val_loss_best = 1000\n",
    "    model_file = f'{kernel_type}_best_fold{fold}.pth'\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=init_lr)\n",
    "    if use_amp:\n",
    "        model, optimizer = amp.initialize(model, optimizer, opt_level=\"O1\")\n",
    "#     if len(os.environ['CUDA_VISIBLE_DEVICES'].split(',')) > 1:\n",
    "    model = nn.DataParallel(model)         \n",
    "#     if fold==1:\n",
    "#         model.load_state_dict(torch.load('densenet121_best_fold1.pth'))\n",
    "#         print(\"load\")\n",
    "    scheduler_cosine = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, cosine_epo)\n",
    "    scheduler_warmup = GradualWarmupSchedulerV2(optimizer, multiplier=10, total_epoch=warmup_epo, after_scheduler=scheduler_cosine)\n",
    "\n",
    "    print(len(dataset_train), len(dataset_valid))\n",
    "\n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        print(time.ctime(), 'Epoch:', epoch)\n",
    "        scheduler_warmup.step(epoch-1)\n",
    "\n",
    "        train_loss = train_epoch(model, train_loader, optimizer)\n",
    "        val_loss, acc, auc = val_epoch(model, valid_loader)\n",
    "    \n",
    "        content = time.ctime() + ' ' + f'Fold {fold}, Epoch {epoch}, lr: {optimizer.param_groups[0][\"lr\"]:.7f}, train loss: {np.mean(train_loss):.5f}, valid loss: {(val_loss):.5f}, acc: {(acc):.4f}, auc: {(auc):.6f}'\n",
    "        print(content)\n",
    "        with open(f'log_{kernel_type}.txt', 'a') as appender:\n",
    "            appender.write(content + '\\n')             \n",
    "            \n",
    "        if val_loss < val_loss_best:\n",
    "            print('val_loss_best ({:.6f} --> {:.6f}).  Saving model ...'.format(val_loss_best, val_loss))\n",
    "            torch.save(model.state_dict(), model_file)\n",
    "            val_loss_best = val_loss\n",
    "\n",
    "    torch.save(model.state_dict(), f'{kernel_type}_model_fold{fold}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run(fold=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run(fold=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run(fold=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run(fold=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run(fold=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run(fold=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir features_rv_lv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.multiprocessing.set_sharing_strategy('file_system')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RSNADataset3D(torch.utils.data.Dataset, Randomizable):\n",
    "    def __init__(self, csv, mode, transform=None):\n",
    "\n",
    "        self.csv = csv.reset_index()\n",
    "        self.mode = mode\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.csv.shape[0]\n",
    "    \n",
    "    def randomize(self) -> None:\n",
    "        MAX_SEED = np.iinfo(np.uint32).max + 1\n",
    "        self._seed = self.R.randint(MAX_SEED, dtype=\"uint32\")    \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        self.randomize()\n",
    "        row = self.csv.iloc[index]\n",
    "        jpg_lst = sorted(glob(os.path.join(data_dir, row.StudyInstanceUID, row.SeriesInstanceUID, '*.jpg')))\n",
    "        img_lst = [cv2.imread(jpg)[:,:,::-1] for jpg in jpg_lst] \n",
    "        img = np.stack([image.astype(np.float32) for image in img_lst], axis=2).transpose(3,0,1,2)\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            if isinstance(self.transform, Randomizable):\n",
    "                self.transform.set_random_state(seed=self._seed)\n",
    "            img = apply_transform(self.transform, img)\n",
    "            \n",
    "        if self.mode == 'test':\n",
    "            return img\n",
    "        else:\n",
    "            return img, torch.tensor(row[target_cols]).float(),row.StudyInstanceUID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_file):\n",
    "        model = monai.networks.nets.densenet.densenet121(spatial_dims=3, in_channels=3, out_channels=out_dim).to(device)\n",
    "\n",
    "        try:  # single GPU model_file\n",
    "            model.load_state_dict(torch.load(model_file), strict=True)\n",
    "        except:  # multi GPU model_file\n",
    "            state_dict = torch.load(model_file)\n",
    "            state_dict = {k[7:] if k.startswith('module.') else k: state_dict[k] for k in state_dict.keys()}\n",
    "            model.load_state_dict(state_dict, strict=True)\n",
    "\n",
    "        model.eval()    \n",
    "        print()\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fold in range(0,5):\n",
    "    df_valid = df_study[(df_study['fold'] == fold)]\n",
    "    dataset_valid = RSNADataset3D(df_valid, 'val', transform=val_transforms)\n",
    "    valid_loader = torch.utils.data.DataLoader(dataset_valid, batch_size=1, num_workers=num_workers)\n",
    "    LOGITS = []\n",
    "    PROBS = []\n",
    "#     try:\n",
    "    model = load_model(f'{kernel_type}_best_fold{fold}.pth')\n",
    "#     except:\n",
    "#         model = load_model(\"densenet121_best_fold4.pth\")\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for data,target,name in tqdm(valid_loader):\n",
    "            data = data.to(device)\n",
    "            target = target.numpy().reshape(-1)\n",
    "            l1 = model(data)\n",
    "            l = torch.sigmoid(l1)\n",
    "            LOGITS.append(l.detach().cpu().numpy().reshape(-1))\n",
    "            PROBS.append(target) \n",
    "            l2 = model.features(data).cpu().numpy()[0]\n",
    "            np.save(f\"features_rv_lv/{name[0]}_3dcnn.npy\",l2)\n",
    "            np.save(f\"features_rv_lv/{name[0]}_3dprob.npy\",l1.cpu().numpy().reshape(-1))\n",
    "    print(fold)\n",
    "    print(confusion_matrix(np.array(PROBS)>0.5,np.array(LOGITS)>0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/media/medicalnfs/Datasets/RSNA/train.csv')\n",
    "df = df[(df.rv_lv_ratio_gte_1 == 0) & ( df.rv_lv_ratio_lt_1==0)].reset_index(drop=True)\n",
    "np.random.seed(0)\n",
    "group_kfold = GroupKFold(n_splits=10)\n",
    "print(group_kfold)\n",
    "\n",
    "df['fold'] = -1\n",
    "for i, (_, val_index) in enumerate(group_kfold.split(df, groups=df.StudyInstanceUID)):\n",
    "    df.loc[val_index, 'fold'] = i\n",
    "model_fold = 0    \n",
    "model = load_model(f'{kernel_type}_model_fold{model_fold}.pth')\n",
    "df.fold.value_counts()\n",
    "df_study = df.drop_duplicates('StudyInstanceUID')[['StudyInstanceUID','SeriesInstanceUID','fold']+target_cols]\n",
    "for fold in range(0,10):\n",
    "    model = load_model(f'{kernel_type}_best_fold{fold%5}.pth')\n",
    "    df_valid = df_study[(df_study['fold'] == fold)]\n",
    "    dataset_valid = RSNADataset3D(df_valid, 'val', transform=val_transforms)\n",
    "    valid_loader = torch.utils.data.DataLoader(dataset_valid, batch_size=1, num_workers=10)\n",
    "    LOGITS = []\n",
    "    PROBS = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for data,target,name in tqdm(valid_loader):\n",
    "            data = data.to(device)\n",
    "            target = target.numpy().reshape(-1)\n",
    "            l1 = model(data)\n",
    "            l = torch.sigmoid(l1)\n",
    "            LOGITS.append(l.detach().cpu().numpy().reshape(-1))\n",
    "            PROBS.append(target) \n",
    "            l2 = model.features(data).cpu().numpy()[0]\n",
    "            np.save(f\"features_rv_lv/{name[0]}_3dcnn.npy\",l2)\n",
    "            np.save(f\"features_rv_lv/{name[0]}_3dprob.npy\",l1.cpu().numpy().reshape(-1))\n",
    "    print(confusion_matrix(np.array(PROBS)>0.5,np.array(LOGITS)>0.5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
