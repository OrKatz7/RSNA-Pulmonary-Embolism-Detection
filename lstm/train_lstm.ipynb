{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import TensorDataset, DataLoader,Dataset\n",
    "import albumentations as albu\n",
    "from skimage.color import gray2rgb\n",
    "import functools\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "import models\n",
    "from data import *\n",
    "from config import *\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from train_utils import trainer\n",
    "from utils import get_train_val\n",
    "import os\n",
    "from apex import amp\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "from tqdm.auto import tqdm\n",
    "from train_utils import trainer\n",
    "from apex import amp\n",
    "import pretrainedmodels\n",
    "from torch import nn\n",
    "import random\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    \n",
    "from losses import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(7777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLD = 0\n",
    "FOLDS=5\n",
    "conf = 'lstm_pe'#'lstm_pe_neg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = eval(conf)\n",
    "mini_dfs,mini_dfs_val = get_train_val(data_config,FOLD,FOLDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import glob\n",
    "import cv2\n",
    "import os\n",
    "from torch.utils.data import TensorDataset, DataLoader,Dataset\n",
    "import albumentations as albu\n",
    "import functools\n",
    "import torch\n",
    "import pydicom\n",
    "import vtk\n",
    "from vtk.util import numpy_support\n",
    "\n",
    "\n",
    "def Zcrop(img,label):\n",
    "    z = np.random.randint(30)/100.0\n",
    "    z1 = np.random.randint(30)/100.0\n",
    "    s = img.shape[0]\n",
    "    start = int(s*z)\n",
    "    end = int((1-z1)*s)\n",
    "    return img[start:end],label[start:end]\n",
    "\n",
    "def spacing(img,label):\n",
    "    z = np.random.randint(1,4)\n",
    "    image = []\n",
    "    labels = []\n",
    "    for row in range(len(img)):\n",
    "        if row%z==0:\n",
    "            image.append(img[row]) \n",
    "            labels.append(label[row]) \n",
    "    return np.array(image),np.array(labels)\n",
    "\n",
    "def randomflip(img,label):\n",
    "    return np.flip(img,0),np.flip(label,0)\n",
    "\n",
    "def randomcrop(img,label):\n",
    "    z = np.random.randint(len(img)//2,len(img)-1)\n",
    "    start = np.random.randint(len(img)-z-1)\n",
    "    end = start+z\n",
    "    return img[start:end],label[start:end]\n",
    "\n",
    "def augment(img,label):\n",
    "    if np.random.randint(3)==0:\n",
    "        img,label = Zcrop(img,label)\n",
    "    elif np.random.randint(2)==0:\n",
    "        img,label = randomcrop(img,label)\n",
    "#     if np.random.randint(3)==0:\n",
    "#         img,label = randomflip(img,label)\n",
    "    return img,label\n",
    "\n",
    "    \n",
    "class CTDatasetLstm(Dataset):\n",
    "    def __init__(self,df,fet_dirs,transforms = None,preprocessing=None):\n",
    "        self.df_main = df\n",
    "        self.fet_dirs = fet_dirs\n",
    "        self.transforms = transforms\n",
    "        self.preprocessing = preprocessing\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        mini = self.df_main[idx].values\n",
    "        fn = glob.glob(f\"../Datasets/RSNA/dicom/train/{mini[0,0]}/*/*.dcm\")[0]\n",
    "        dc = pydicom.dcmread(fn, stop_before_pixels=True )\n",
    "        RES = {}\n",
    "        for i in list(dc.keys()):\n",
    "            RES[dc[i].description()] = dc[i].value\n",
    "        meta = np.zeros([9])\n",
    "        meta[0:6] = np.array(RES['Image Orientation (Patient)'])\n",
    "        meta[6:8] = np.array(RES['Pixel Spacing'])/10\n",
    "        meta[8] = np.array(RES['Slice Thickness'])/10\n",
    "        paths = [glob.glob(f\"{fdir}/{mini[0,0]}.npy\")[0] for fdir in self.fet_dirs]\n",
    "        x_scans = [np.load(p) for p in paths]\n",
    "        try:\n",
    "            x = np.concatenate(x_scans,axis=1)\n",
    "        except:\n",
    "            print(mini[0,0])\n",
    "            return self.__getitem__(np.random.randint(self.__len__()))\n",
    "        global_rv_lv = np.load(f\"../cnn3d/features_rv_lv/{mini[0,0]}_3dcnn.npy\")\n",
    "        global_rlc = np.load(f\"../cnn3d/features_densenet121_rlc/{mini[0,0]}_3dcnn.npy\")\n",
    "        global_pe = np.load(f\"../cnn3d/features_densenet121_pe/{mini[0,0]}_3dcnn.npy\")\n",
    "        label = mini[:,3:-1].astype(int)\n",
    "        p = self.df_main[idx].groupby('StudyInstanceUID').max().values[0][2:-1]\n",
    "        label0 = np.array([p[0],p[1],p[9]])\n",
    "        label1 = np.array([p[2],p[3],abs(1-p[0])])\n",
    "        label2 = np.array([p[5],p[7],abs(1-p[0]),abs(1-p[5]-p[7]-abs(1-p[0]))])\n",
    "        label3 = np.array([p[6],p[4],p[8]])\n",
    "        if self.transforms:\n",
    "            x,label = self.transforms(x,label)\n",
    "        return global_rv_lv,global_rlc,global_pe,np.array(x),torch.from_numpy(label[:,0]),torch.from_numpy(np.array([label0,label1,label3])),torch.from_numpy(label2)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df_main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CTDatasetLstm(mini_dfs,model_config.dirs,transforms=None,preprocessing=None)#augment\n",
    "val_dataset = CTDatasetLstm(mini_dfs_val,model_config.dirs,transforms=None,preprocessing=None)\n",
    "train = DataLoader(train_dataset, batch_size=1, shuffle=True, num_workers=10, pin_memory=False)\n",
    "val = DataLoader(val_dataset, batch_size=1, shuffle=False, num_workers=10, pin_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_x,g_y,g_z,x,y,y1,y3 = val_dataset[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import torch\n",
    "\n",
    "sigmoid = nn.Sigmoid()\n",
    "\n",
    "\n",
    "\n",
    "class Swish(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, i):\n",
    "        result = i * sigmoid(i)\n",
    "        ctx.save_for_backward(i)\n",
    "        return result\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        i = ctx.saved_variables[0]\n",
    "        sigmoid_i = sigmoid(i)\n",
    "        return grad_output * (sigmoid_i * (1 + i * (1 - sigmoid_i)))\n",
    "\n",
    "\n",
    "class Swish_Module(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return Swish.apply(x)\n",
    "    \n",
    "class GaussianNoise(nn.Module):\n",
    "    def __init__(self, sigma=0.1, is_relative_detach=True):\n",
    "        super().__init__()\n",
    "        self.sigma = sigma\n",
    "        self.is_relative_detach = is_relative_detach\n",
    "        self.noise = torch.tensor(0).cuda().float()\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.training and self.sigma != 0:\n",
    "            scale = self.sigma * x.detach() if self.is_relative_detach else self.sigma * x\n",
    "            sampled_noise = self.noise.repeat(*x.size()).normal_() * scale\n",
    "            x = x + sampled_noise\n",
    "        return x \n",
    "\n",
    "class NeuralNet2(nn.Module):\n",
    "    def __init__(self, embed_size=5379, LSTM_UNITS=512, DO = 0.2,g=0.05):\n",
    "        super(NeuralNet2, self).__init__()\n",
    "        self.lstm1 = nn.LSTM(embed_size, LSTM_UNITS, bidirectional=True, batch_first=True,dropout=0.0)\n",
    "        self.lstm2 = nn.LSTM(LSTM_UNITS * 2, LSTM_UNITS, bidirectional=True, batch_first=True,dropout=0.0)\n",
    "        self.Noise = GaussianNoise(g)\n",
    "        self.linear1 = nn.Linear(LSTM_UNITS*2, LSTM_UNITS*2)\n",
    "        self.linear2 = nn.Linear(LSTM_UNITS*2, LSTM_UNITS*2)\n",
    "        self.avd3d = nn.AdaptiveAvgPool3d(1)\n",
    "        self.avd1d = nn.AdaptiveAvgPool1d(1)\n",
    "        \n",
    "        self.linear_rv = nn.Linear(LSTM_UNITS*2, LSTM_UNITS*2)\n",
    "        self.linear_rlc = nn.Linear(LSTM_UNITS*2, LSTM_UNITS*2)\n",
    "        self.linear_pe = nn.Linear(LSTM_UNITS*2, LSTM_UNITS*2)\n",
    "        \n",
    "        self.linear_pe = nn.Linear(LSTM_UNITS*2, 1)\n",
    "        self.linear_global_fc0 = nn.Linear(LSTM_UNITS*2*2, 3) #ALL_PE,NEG,IND\n",
    "        self.linear_global_fc1 = nn.Linear(LSTM_UNITS*2*2, 3) #RV>1,RV<1,Not PE\n",
    "        self.linear_global_fc2 = nn.Linear(LSTM_UNITS*2*2, 4) #Chronic, Chronic+Acute, Not PE,Acute\n",
    "        self.linear_global_fc3 = nn.Linear(LSTM_UNITS*2*2, 3) #right,left,center\n",
    "        self.dropuot3d = nn.Dropout3d(DO)\n",
    "        self.dropuot1d = nn.Dropout(DO)\n",
    "        self.s3d = Swish_Module()\n",
    "        self.s1d = Swish_Module()\n",
    "        self.s2d = Swish_Module()\n",
    "\n",
    "\n",
    "    def forward(self, x, x_rv,x_rlc,x_pe):\n",
    "        x_rv = self.dropuot3d(x_rv)\n",
    "        x_rv = self.avd3d(x_rv).reshape(1,-1)\n",
    "        x_rv1 = self.s3d(self.linear_rv(x_rv))\n",
    "        x_rv = x_rv.reshape(1,-1)\n",
    "        x_rv1 = x_rv1.reshape(1,-1)\n",
    "        \n",
    "        \n",
    "        x_rlc = self.dropuot3d(x_rlc)\n",
    "        x_rlc = self.avd3d(x_rlc).reshape(1,-1)\n",
    "        x_rlc1 = self.s3d(self.linear_rlc(x_rlc))\n",
    "        x_rlc = x_rlc.reshape(1,-1)\n",
    "        x_rlc1 = x_rlc1.reshape(1,-1)\n",
    "        \n",
    "        \n",
    "        x_pe = self.dropuot3d(x_pe)\n",
    "        x_pe = self.avd3d(x_pe).reshape(1,-1)\n",
    "        x_pe1 = self.s3d(self.linear_pe(x_pe))\n",
    "        x_pe = x_pe.reshape(1,-1)\n",
    "        x_pe1 = x_pe1.reshape(1,-1)\n",
    "        \n",
    "        b,f = x.shape\n",
    "        embedding = x.reshape(1,b,f)\n",
    "        self.lstm1.flatten_parameters()\n",
    "        h_lstm1, _ = self.lstm1(embedding)\n",
    "        self.lstm2.flatten_parameters()\n",
    "        h_lstm2, _ = self.lstm2(h_lstm1)\n",
    "        \n",
    "        h_conc_linear1  = self.s1d(self.linear1(h_lstm1))\n",
    "        h_conc_linear2  = self.s2d(self.linear2(h_lstm2))\n",
    "        hidden = h_lstm1 + h_lstm2 + h_conc_linear1 + h_conc_linear2\n",
    "        \n",
    "\n",
    "        \n",
    "        output = self.linear_pe(hidden)\n",
    "        \n",
    "        hidden2 = self.avd1d(hidden.transpose(2,1))\n",
    "        hidden_rv = torch.cat([hidden2[:,:,0],x_rv+x_rv1],-1)\n",
    "        hidden_rlc = torch.cat([hidden2[:,:,0],x_rlc+x_rlc1],-1)\n",
    "        \n",
    "        hidden_global = torch.cat([hidden2[:,:,0],x_pe],-1)\n",
    "        output_global0 = self.linear_global_fc0(hidden_global)\n",
    "    \n",
    "        output_global1 = self.linear_global_fc1(hidden_rv)\n",
    "        \n",
    "        output_global2 = self.linear_global_fc2(hidden_global)\n",
    "        \n",
    "        output_global3 = self.linear_global_fc3(hidden_rlc)\n",
    "        return output,output_global0,output_global1,output_global2,output_global3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size = x.shape[1]\n",
    "embed_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import os\n",
    "from apex import amp\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import os\n",
    "from apex import amp\n",
    "class trainer:\n",
    "    def __init__(self,loss_fn,model,optimizer,scheduler,config):\n",
    "        self.loss_fn = loss_fn\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.scheduler = scheduler\n",
    "        self.config = config\n",
    "        self.metric = loss_fn\n",
    "        self.CE = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "        \n",
    "    def batch_train(self, x3d,x3d1,x3d2,batch_imgs, batch_labels0,batch_labels1,lebal3, batch_idx,e):\n",
    "        batch_imgs = batch_imgs.cuda().float()[0]\n",
    "        x3d = x3d.cuda().float()\n",
    "        x3d1 = x3d1.cuda().float()\n",
    "        x3d2 = x3d2.cuda().float()\n",
    "        predicted = self.model(batch_imgs,x3d,x3d1,x3d2)\n",
    "        batch_labels1 = batch_labels1[0]\n",
    "        loss0,l0,rsna = self.loss_fn(predicted,batch_labels0,batch_labels1,lebal3)\n",
    "        loss = rsna\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        self.optimizer.zero_grad()\n",
    "        return l0.item(), predicted,rsna.detach().cpu().numpy(),loss0.item()\n",
    "\n",
    "    def train_epoch(self, loader,e):\n",
    "        self.model.train()\n",
    "        tqdm_loader = tqdm(loader)\n",
    "        current_loss_mean = 0\n",
    "        rsna_all = 0\n",
    "        loss_per_image = 0\n",
    "        for batch_idx, (x3d,x3d1,x3d2,imgs,labels,labels1,lebal3) in enumerate(tqdm_loader):\n",
    "            loss, predicted,rsna,loss0 = self.batch_train(x3d,x3d1,x3d2,imgs, labels,labels1,lebal3, batch_idx,e)\n",
    "            current_loss_mean = (current_loss_mean * batch_idx + loss) / (batch_idx + 1)\n",
    "            rsna_all = (rsna_all * batch_idx + rsna) / (batch_idx + 1)\n",
    "            loss_per_image = (loss_per_image * batch_idx + loss0) / (batch_idx + 1)\n",
    "            tqdm_loader.set_description('loss: {:.4} rsna:{:.4}  im:{:.4} lr:{:.4}'.format(\n",
    "                    current_loss_mean,rsna_all,loss_per_image, self.optimizer.param_groups[0]['lr']))\n",
    "        return current_loss_mean\n",
    "    \n",
    "    def valid_epoch(self, loader,name=\"valid\"):\n",
    "        self.model.eval()\n",
    "        tqdm_loader = tqdm(loader)\n",
    "        current_loss_mean = 0\n",
    "        current_loss_mean_image = 0\n",
    "        current_loss_mean_scan = 0\n",
    "        correct = 0\n",
    "        loss_pre_class =[]\n",
    "        rsna_all = []\n",
    "        for batch_idx, (x3d,x3d1,x3d2,imgs,labels0,labels1,lebal3) in enumerate(tqdm_loader):\n",
    "            with torch.no_grad():\n",
    "                batch_imgs = imgs.cuda().float()[0]\n",
    "                x3d = x3d.cuda().float()[0]\n",
    "                x3d1 = x3d1.cuda().float()[0]\n",
    "                x3d2 = x3d2.cuda().float()[0]\n",
    "                batch_labels0 = labels0.cuda().float()\n",
    "                batch_labels1 = labels1[0]\n",
    "                predicted = self.model(batch_imgs,x3d,x3d1,x3d2)\n",
    "                loss0,l0,l1 = self.loss_fn(predicted,batch_labels0,batch_labels1,lebal3)\n",
    "                rsna_all.append(l1.cpu().numpy())\n",
    "                loss = l0.item()\n",
    "                current_loss_mean = (current_loss_mean * batch_idx + loss) / (batch_idx + 1)\n",
    "                current_loss_mean_image = (current_loss_mean_image * batch_idx + l1.item()) / (batch_idx + 1)\n",
    "                current_loss_mean_scan = (current_loss_mean_scan * batch_idx + loss0) / (batch_idx + 1)\n",
    "                tqdm_loader.set_description(f\"loss : {current_loss_mean:.4}, rsna : {current_loss_mean_image:.4}, image : {current_loss_mean_scan:.4}\")\n",
    "        print(f\"rsna - {np.mean(rsna_all)}\")\n",
    "        score = 1-current_loss_mean\n",
    "        print('metric {}'.format(score))\n",
    "        return 1-np.mean(rsna_all)\n",
    "    \n",
    "    def run(self,train_loder,val_loder):\n",
    "        best_score = -100000\n",
    "        for e in range(self.config.epochs):\n",
    "            print(\"----------Epoch {}-----------\".format(e))\n",
    "            current_loss_mean = self.train_epoch(train_loder,e)\n",
    "            score = self.valid_epoch(val_loder)\n",
    "            self.scheduler.step()\n",
    "            if best_score < score:\n",
    "                best_score = score\n",
    "                torch.save(self.model.state_dict(),self.config.MODEL_PATH+\"/{}_best.pth\".format(self.config.model_name))\n",
    "                print(self.config.MODEL_PATH+\"/{}_best.pth\".format(self.config.model_name))\n",
    "\n",
    "            \n",
    "    def load_best_model(self):\n",
    "        if os.path.exists(self.config.MODEL_PATH+\"/{}_best.pth\".format(self.config.model_name)):\n",
    "            self.model.load_state_dict(torch.load(self.config.MODEL_PATH+\"/{}_best.pth\".format(self.config.model_name)))\n",
    "            print(\"load best model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for g in [0.05]:\n",
    "    for DO in [0.5]:\n",
    "        print(\"*************************************************************************\")\n",
    "        print(f\"dropout {DO}, Noise {g}\")\n",
    "        model = NeuralNet2(embed_size=embed_size,DO=DO,g=g).cuda()#,model_num=x.shape[0]).cuda()#, **model_config.models_pram).cuda()\n",
    "        model.cuda()\n",
    "        param_optimizer = list(model.named_parameters())\n",
    "        no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "        plist = [\n",
    "            {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.00001},\n",
    "            {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "            ]\n",
    "        optimizer = eval(model_config.optimizer)(plist,**model_config.optimizer_parm)\n",
    "        scheduler = eval(model_config.scheduler)(optimizer,**model_config.scheduler_parm)\n",
    "        loss_fn = eval(model_config.loss_fn)()\n",
    "        model_config.model_name = model_config.model_name + \"_fold_\" +str(FOLD)\n",
    "        print(scheduler,model_config.scheduler_parm,model_config.optimizer_parm)\n",
    "        Trainer = trainer(ComboLoss(),model,optimizer,scheduler,config=model_config)\n",
    "        Trainer.run(train,val)\n",
    "        print(\"*************************************************************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v= iter(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Trainer.load_best_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as mpatches\n",
    "Trainer.model.eval()\n",
    "x3d,x3d1,x,y,y1,y2 = next(v)\n",
    "with torch.no_grad():\n",
    "    pred = Trainer.model(x.cuda().float()[0],x3d.cuda().float(),x3d1.cuda().float())\n",
    "    res = torch.sigmoid(pred[0].reshape(-1)).detach().cpu().numpy().reshape(-1)\n",
    "    res1 = torch.softmax(pred[1],dim=1).cpu().numpy().reshape(-1).tolist()\n",
    "    res1 = res1+ torch.softmax(pred[2],dim=1).cpu().numpy().reshape(-1).tolist()\n",
    "    res1 = res1+torch.sigmoid(pred[4]).cpu().numpy().reshape(-1).tolist()\n",
    "    res1 = res1+torch.softmax(pred[3],dim=1).cpu().numpy().reshape(-1).tolist()\n",
    "    y_numpy = y.detach().cpu().numpy().reshape(-1)\n",
    "    y1_numpy = y1.detach().cpu().numpy().reshape(-1).tolist() + y2.detach().cpu().numpy().reshape(-1).tolist() \n",
    "plt.figure(figsize=[15,8])\n",
    "plt.subplot(131)\n",
    "plt.plot(y_numpy,label='gt',color='blue')\n",
    "# plt.plot(res/2+torch.sigmoid(x[0,:,:,-1]).cpu().numpy()/2,label='pred',color='green')\n",
    "plt.plot(res,label='pred',color='red')\n",
    "plt.xlabel(\"slices\")\n",
    "plt.ylabel(\"PE\")\n",
    "plt.ylim(0, 1.3)\n",
    "plt.title(\"lstm\")\n",
    "red_patch = mpatches.Patch(color='red', label='pred')\n",
    "blue_patch = mpatches.Patch(color='blue', label='gt')\n",
    "plt.legend(handles=[red_patch,blue_patch])\n",
    "plt.subplot(132)\n",
    "plt.plot(y_numpy,label='gt',color='blue')\n",
    "plt.plot(torch.sigmoid(x[0,:,2048]).cpu().numpy(),color='green')\n",
    "# plt.plot(torch.sigmoid(x[0,0,:,2048]).cpu().numpy(),color='red')\n",
    "plt.ylim(0, 1.3)\n",
    "plt.title(\"classification - EfficientNet B5\")\n",
    "plt.subplot(133)\n",
    "plt.plot([\"PE\",\"NEG\",\"IND\",\"RV>1\",\"RV<1\",\"NPE\",\"R\",\"L\",\"C\",\"CH\",\"CH+AC\",\"NPE2\",\"AC\"],y1_numpy,'o', color='red',label='gt')\n",
    "plt.plot(res1,'o', color='blue',label='pe')\n",
    "# plt.subplot(133)\n",
    "# plt.bar(np.arange(len(y1_numpy)),y1_numpy-res1)\n",
    "# plt.ylim(-1, 1)\n",
    "plt.show()\n",
    "print(x[0].shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
